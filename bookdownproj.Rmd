--- 
title: "R Coding Compendium"
author: "Ryan Schneider"
date: "`r Sys.Date()`"
site: bookdown::bookdown_site
---

# A Monument to my Madness

This book contains all my personal coding notes from the last two years. Why am I doing this? Probably because I'm a glutton for punishment, and I'd rather procrastinate than write my dissertation proposal.

## What this book is, and what it is not

You know those absolutely amazing, comprehensive guides where you can learn everything you need to know about R? Specifically, [this one](https://r4ds.had.co.nz/) by Hadley Wickham? Yeah, this isn't that.

This book is designed as a ***quick reference guide*** for many of the most common things you'll need to do in everyday data analysis and research. Think of it like a coding dictionary, as opposed to a manual, or a full-blown book like Wickham's. If you want (or need) to learn about a subject or command *in-depth*, then you should probably use Wickham's book or [the tidyverse websites](https://www.tidyverse.org/packages/); however, if you're just looking for a quick "what command do I need to accomplish XYZ", you've come to the right place.

Oh and by the way, much of this whole quick reference guide thing is based on the tidyverse, so if you're not already familiar with it and need a quick intro before beginning, check out [these slides](https://oliviergimenez.github.io/intro_tidyverse/#1) and watch a few YouTube videos.

<!--chapter:end:index.Rmd-->

# Introduction: R Basics

There are lots of things you can do with base R commands, but this notebook focuses on the tidyverse. These packages (below) improve on almost every single aspect of base R's functioning, and make different tasks far easier, more code efficient, and faster. 



readr for example, replaces the base read.xyz commands and greatly enhances functionality for reading in data.
The forcats package makes manipulating factors a breeze, and stringr makes searching through and manipulating vectors of strings super easy. Purrr is for semi-advanced uses (e.g. For loops) that you probably won't use early on, but will be essential and invaluable if you have some iterative or repetitive code or task you want to perform. tidyr is amazing for getting clean data sets upon import.

Let's get stuck in.

```{r}
library(tidyverse)
```


## Importing Data

Can you import via RStudio's GUI? Yes...but often times it's just as easy (or easier) to import via a written command. Several examples below for different file types.


### Spreadsheets


```{r}

```


### Comma-Separated Values (CSV) Files



## Exporting (i.e., saving) Data and Output


### Export to .csv


### Export to .RData (or .RDS)



### Export to Excel

```{r}
library(openxlsx)

#Method 1: If you only want to export 1 thing, and/or only need output document
  #write as object, with no formatting:
  write.xlsx(objectname,file = "filenamehere.xlsx",colnames=TRUE, borders="columns")

  #write as table:
  write.xlsx(objectname,"filename.xlsx",asTable = TRUE)


#Method 2: If you want to do the above, but add multiple objects or tables to one workbook/file:
  ## first Create Workbook object
  wb <- createWorkbook("AuthorName")
  #then add worksheets (as many as desired)
  addWorksheet(wb, "worksheetnamehere")
#then write the object to the worksheet  
writeData(wb, "test", nameofobjectordataframe, startCol = 2, startRow = 3, rowNames = TRUE)

#save excel file
saveWorkbook(wb, "filenamehere.xlsx", overwrite =TRUE)


#Method 3: exact same as method 2, but creating a more fancy tables

wb <- createWorkbook("Ryan")
addWorksheet(wb, "worksheetnamehere")
writeDataTable(wb, sheetName, objectName, startCol = 1, startRow = 1, colNames = TRUE, rowNames = FALSE,
          tableStyle="TableStyleLight2",tableName=NULL, headerStyle = NULL,withFilter=FALSE,keepNA=TRUE,sep=", ",
          stack = FALSE, firstColumn = FALSE, lastColumn = FALSE,bandedRows = TRUE,bandedCols = FALSE)

saveWorkbook(wb, "filenamehere.xlsx", overwrite =TRUE)

```


<!--chapter:end:02-basics.Rmd-->

# Wrangle Data

This chapter contains useful tips on wrangling (i.e., manipulating) data. If you need to know to do to things like create new variables, split one variable into multiple variables, pivot a data set from wide to long, etc., look no further.

If you want a pretty good intro tutorial to the `dplyr` package, click [here](https://www-r--bloggers-com.cdn.ampproject.org/v/s/www.r-bloggers.com/2021/01/how-to-analyze-data-with-r-a-complete-beginner-guide-to-dplyr/amp/?amp_js_v=a6&gsa=1&usqp=mq331AQFKAGwASA%3D#csi=0&referrer=https%3A%2F%2Fwww.google.com&tf=From%20%251%24s&ampshare=https%3A%2F%2Fwww.r-bloggers.com%2F2021%2F01%2Fhow-to-analyze-data-with-r-a-complete-beginner-guide-to-dplyr%2F)

## Joining or Splitting

Joining and splitting data is pretty straightforward....

### Whole Data Sets

The code below is from [this excellent tutorial](https://www.youtube.com/watch?v=SCdmyyoudb8&t=23s)

```{r}
set.seed(2018)

df1=data.frame(customer_id=c(1:10),
               product=sample(c('toaster','TV','Dishwasher'),10,replace = TRUE))


df2=data.frame(customer_id=c(sample(df1$customer_id, 5)),state=sample(c('New York','California'),5,replace = TRUE))

df1=tibble::as_tibble(df1)
df2=tibble::as_tibble(df2)

# df1 =left table
# df2= right table
```

Inner join - retains only rows with values that appear in both tables, and matches by keys.

*If you're joining two Qualtrics surveys together, this is most likely the one you want to use (e.g. matching by participant name, and only keeping rows in the joined data set for participants that have responses logged in both survey 1 and survey 2*
```{r}
df1 %>% inner_join(df2,by='customer_id')
```

Left join - returns everything in the left, and rows with matching keys in the right
```{r}
df1 %>% left_join(df2,by='customer_id')
```

Right join - returns everything in the right, and rows with matching keys in the left
```{r}
df1 %>% right_join(df2,by='customer_id')

# note: example if the customer id column was named something different in the second df
    #df1 %>% left_join(df2,by=c('customer_id'='name2'))
```

Full join - retain all rows from both tables, and join matching keys in both right and left
```{r}
df1 %>% full_join(df2,by='customer_id')
```

Anti join - returns all rows in the left that do not have matching keys in the right
```{r}
df1 %>% anti_join(df2,by='customer_id')
```


### Individual Columns/Variables

Splitting or joining columns is much easier than doing it to whole data sets. You can use `dplyr::separate()` to accomplish the former, and `dplyr::unite()` for the latter.

```{r}
print("hello")
```


## Selecting specific columns/variables

Sometimes when working with a data set, you want to work with a few *specific* variables. For instance, maybe you want to view a graph of only reverse-coded variables (which start with the prefix "r"); or maybe you want to create a subset of your data that has a few specific variables removed. For this you can use `dplyr::select()` and its associated helper commands

`select()` can be thought of as "extract"; it tells R to identify and "extract" a specific variable (or variables)


```{r eval=FALSE}
cars=mtcars

# select one column
cars %>% select(mpg)

# select multiple columns, if they are all next to one another
cars %>% select(mpg:hp)

# select multiple columns by name (when not next to one another) by defining them in a vector
cars %>% select(c(mpg, hp, wt))

# select only variables that start with a certain prefix/character/pattern/etc.
cars %>% select(starts_with("d"))

# ...or columns that end with a certain prefix/etc.
cars %>% select(ends_with("t"))

# ...or contains a certain pattern or string
cars %>% select(contains("se"))

# select ALL OF the variables in a data set that match those of a pre-defined vector
  
  # first define the names in a vector
  vars=c("hp", "drat", "gear", "carb")
  
  #now use helper
  cars %>% select(all_of(vars))
  
# select ANY OF the variables in a pre-defined vector
  
  vars_2=c("hp", "drat", "watermelon", "grilled_cheese") # only the first two will be in the data
  
  cars %>% select(any_of(vars_2)) # only (and all of) the variables actually PRESENT in the data are pulled
  
# select only variables of a certain class or type
  cars %>% select(where(is.numeric))
  cars %>% select(where(is.character))
```


Other examples can be seen on [THIS LINK](https://tidyselect.r-lib.org/reference/language.html) for a simple but detailed guide.



## If, If-then, and Case-when

### If-then
The premise of an if/then or if/else statement is simple: "If condition 1 is satisfied, perform x operation; if not, then do y"

```{r}
iris %>% mutate(length_check=ifelse(iris$Sepal.Length<5, "short", "long")) # if the length in Sepal.Length is >5, set new variable = to "short"; else, set it to "long"
```


### Case-when

When you have 3+ conditions, it's easier to use case-when. This is a more simple and straightforward approach than nesting multiple if-else commands

```{r eval=FALSE}
My_vector= case_when(
	Condition1 ~ value1,
	Condition2 ~ value2,
	Condition3 ~ value3
	TRUE ~ valueForEverythingElse #catch all for things that don't meet the above conditions
	)
```

Example:
```{r}

mtcars %>% mutate(test= case_when(cyl==4 ~ "small",
                                  cyl==6 ~ "medium",
                                  cyl==8 ~ "large")) %>% 
  select(c(cyl,test))
```



## Merge or Collapse variables

Sometimes you'll have multiple variables and you want to collapse them into a single variable. The `pmin()` command is useful for this

```{r}
example_data=tribble(~A,~B,~C,
                     1,NA,NA,
                     2,NA,NA,
                     3,NA,NA,
                     NA,4,NA,
                     NA,5,NA,
                     NA,6,NA,
                     NA,NA,7,
                     NA,NA,8,
                     NA,NA,9)

example_data %>%
  mutate(accept_reject = 
           pmin(A,B,C,na.rm = TRUE))
```



## Apply a function to multiple variables at once

You can either specify each column individually, like above, or tell R to identify columns for you based on their type or their name. This requires adding in one additional verb--either contains() or where() depending on what you want to do.

Two simple examples:

```{r}
# turn multiple variables into factors
ex_data=dplyr::tribble(~color, ~car,
                       "red", "corvette",
                       "blue", "chevelle",
                       "green", "camaro",
                       "red", "corvette",
                       "green", "chevelle",
                       "yellow", "gto")

dplyr::glimpse(ex_data)

ex_data %>% mutate(across(c(color, car),factor))

# round multiple columns to 1 decimal place
mtcars %>% mutate(across(c(disp:qsec),round,1))
```


## Pivoting (i.e., transposing) data

### Condense multiple rows into a single column (pivot wide to long)

Rearranging data like this can make it easier to work with and analyze. Example below from my gradebook for stats (exported from Canvas). The original file had every assignment in its own column, but that is a pain when you're trying to analyze sums, patterns, etc. across people and assignment categories.

```{r eval=FALSE}
# general command structure
 pivot_longer( # Transpose lengthwise by:
    cols = everything(), # Taking ALL variable names...
    names_to="variable", # ...and dumping them into this new variable
    values_to="missing_count") #...then place their values in this new column
```

**NOTE!!!** Pivoting data from wide to long like this expands the number of rows to make a matrix so that (for example, each student now has as a row for each assignment). Therefore, you can only pivot longways (or wide) **ONCE**, otherwise you will make duplicates. 

*If you need to pivot multiple columns, just include all of the columns in one single pivot; do not use two separate, back to back pivot commands.*

Example:

```{r}
gradebook=tibble::tribble(
  ~Student, ~Homework.1, ~Homework.2, ~Homework.3, ~Homework.4, ~Homework.5, ~Quiz.1, ~Quiz.2, ~Quiz.3, ~Quiz.4, ~Final,
     "Bob",         19L,          0L,          13,          16,          0L,      21,      7L,      15,    17.5,     33,
    "Jane",         17L,         19L,          16,        16.5,         25L,    21.5,     19L,   14.75,     9.5,   39.5,
    "John",         19L,         19L,        14.5,        19.5,         25L,      21,     21L,    18.5,      17,   46.5
  )

gradebook=gradebook %>% 
   pivot_longer( # Transpose lengthwise by:
    cols = Homework.1:Final, # Taking these variables
    names_to="Assignment", # ...and dumping them into this new variable, storing them lengthwise
    values_to="Points") #...then place their values in this new column

gradebook
```


## Managing Many Models

Imagine the concept of Russian Dolls, applied to data sets. You can manage data sets more effectively my collapsing them into a single tiny, mini data frame, and stuffing that inside of another one.

This is done via "nesting"...

Effectively, you smush/collapse everything down so it fits inside one column. You can unnest to expand this data back out later when you need it, and keep it collapsed when you don't. Code works like this:

```{r eval=FALSE}
by_country=gapminder::gapminder %>% 
  group_by(continent,country) %>% # indicate the variables to keep at the top level
  nest() # smush the rest into a list-column


country_model=function(df){
  lm(lifExp~year1950,data = df)
}

# Transform a list of models into a df
models=by_country %>% 
  mutate(mod=map(data,country_model))
```

- You can store anything in a data frame. You can keep the df connected to the model, which makes it very easy to manage a whole slew of related models
- You can use functional programming (i.e., iterative functions) to map functions or combinations of functions in new ways.
- Converting data into tidy data sets gives you a whole new way (and easier way) to manage lots of information

Below is the full script I copied from Hadley Wickham's lecture, which you can watch [here](https://www.youtube.com/watch?v=rz3_FDVt9eg)

```{r eval=FALSE}

pacman::p_load(dplyr,purrr,tidyverse,gapminder)

#### Workflow for managing many models in R ####
# 1. Nest data with {tidyr}
# 2. Use {purrr} to map a modeling function
# 3. Use {broom} to inspect your tidy data


gapminder=gapminder %>% 
  mutate(year1950= year-1950) #the number of years it's been since 1950

#--------------------------------------------------------------------------------------------
#### Step 1. Nest the data. ####

# A nested data frame has one column per country. You're essentially 
# creating a Russian doll; a data frame inside of a larger data frame.

by_country=gapminder %>% 
  group_by(continent,country) %>% # variables to keep at the top level
  nest() # smush everything else into a df, and store this mini-df in its own column

# with this, you can have an entire table per row; a whole data frame for each country
# Essentially condensing a list into a table
by_country$data[[1]]


#--------------------------------------------------------------------------------------------

#### Step 2. Use purrr to map stuff. ####

# 12:50
country_model=function(df){
  lm(lifeExp ~ year1950, data = df)
}

models= by_country %>% 
  mutate(
    mod=map(data,country_model)
  )


gapminder %>% 
  group_by(continent,country) %>% 
  nest() %>% 
  mutate(
    mod= data %>% map(country_model)
  )

# 27:11

#--------------------------------------------------------------------------------------------
##### Step 3. ####

# This creates another nested df inside of your main data frame that has the summary stats of each model
models=models %>% mutate(
  tidy=map(mod, broom::tidy), # tidy() gives model estimates
  glance=map(mod,broom::glance), # glance() gives model summaries
  augment=map(mod,broom::augment) # model coefficients
)

# What can you do with this nest of data frames? 
# The reverse of step 1; un-nest it to unpack everything!
# 34:40
# Keeps a massive list of related information neatly organized!

unnest(models,data) # back to where we started
unnest(models,glance, .drop = TRUE) 
unnest(models,tidy) 
```

...and here is a version I made of the above to manage many Bayesian models. Admittedly, I'm not really sure how useful this is though.

```{r eval=FALSE}
# CONDENSED MASTER TABLE VERSION -----------------------------------------------------------------------------
# Models table that has all models condensed

models=tribble(~Model_name, ~model_descrip, ~model,
               "Thesis_Model", "Discount and PTS", Thesis_Model,
               "discount_model", "Discount variable only", discount_model,
               "PTS_model", "PTS variable only", PTS_model
)

# Clean up work space
#rm(DiscountPrior,Priors_MEmodel,Priors_Interactionmodel)

# Grab and store all model info 
models=models %>% 
  mutate(prior_info=map(model,describe_prior),
         posterior_info=map(model, describe_posterior_fancy),
         model_performance=map(model,performance::performance)
         
  )

# DO NOT TRY AND VIEW THE TABLE IN A WINDOW!!!! RStan objects are so large they cause R to lock up
# Call the model in the console instead

#### summon individual model stats ####
describe_prior(models$model[[1]]) #by specific model
map(models$model,describe_prior) # do for all models at once

# or all info for all models at once
unnest(models,posterior_info) %>% 
  select(-c(model,prior_info,model_descrip))
```


## Turn row names into a column/variable

Use the `rownames()` command to turn row names into a variable

```{r}
rownames_to_column(mtcars, var = "car")
```

## How to edit/change column names

TWO WAYS TO DO THIS: Use `colnames()` (for base R) or `rename()` (for tidyverse)

`colnames()` pulls up all the column/variable names as a vector. If you want to actually change them, you'll need to combine this command with something like the sub() or gsub() commands (for base R). I'm going to skip this because...its base R.

To access and change the names faster via tidyverse, run use `rename()`
```{r}
iris=as_tibble(iris)

iris %>% rename("Sepal.blaahhhhhh"="Sepal.Length")

iris %>% rename("hurr"="Sepal.Length",
                "durr"="Sepal.Width",
                "abcdefgh"="Species")
```


If you need to do some really fancy conditional renaming (e.g., changing all variables that start with "r" to start with "rf" instead, to make it more clear that the prefix actually stands for "risk factor" rather than "reverse coded"), you'll need to use `rename_with()`. 

This command has two parts to it: the data set, and the function you wish to apply to it (which you put after the `~`)

```{r}
rename_with(iris, ~ gsub(pattern = ".", replacement = "_", .x, fixed = TRUE))
```

The gsub() function from Base R identifies matching patterns in the data and substitutes them with what you want instead. Think of it like a "Find all and replace with" function

The above line thus does the following:
	1. Checks the column names of the supplied data set (iris) for a specific pattern (pattern= )
	2. Replaces said pattern with your input (replacement= )

The great thing about rename_with() is that the .fn (or `~` shortcut) can take ANY function as input. For example, if you want to add a prefix or suffix to columns, you can change the function to:

```{r}
rename_with( iris, ~ paste0(.x,  "_text"))
```

The above line adds a suffix. You can also add a prefix in the exact same way, just by switching the order of the string and the pattern in the paste0 command


***Alternative method to the above***
This is a second way to do the above. It may appear more simple, but it's also probably not as theoretically consistent with how the packages were made…..it uses the {stringr} package to rename the column names, and {stringr} is typically for editing vectors of strings…..
…so it works, but it's a little unconventional because you call and edit the column names like they're a vector in a data set

```{r}
colnames(iris)=str_replace(colnames(iris), pattern = ".", replacement = "_")
```

## Re-order columns in a data set

Use `relocate()` to change column positions, using the same syntax as `select()` to make it easy to move blocks of columns at once.

```{r}
relocate(diff_in_days, .before=NULL, .after = end_date)

mtcars # notice the column order

mtcars %>% relocate(hp, .before = mpg)

mtcars %>% relocate(hp:wt, .after= am)
```


<!--chapter:end:03-wrangle.Rmd-->

# Clean Data

## Replace a value with NA

Use `dplyr::na_if()` if you have a value coded in your data (e.g., 999) that you want to convert to NA

```{r}
FullPop$current_age=na_if(FullPop$current_age,999)

jlwop_messy %>% 
  mutate(rf_removed=na_if(rf_removed, 7))
```

**Note.** `tidyr::replace_na()` does exactly the same thing. You can use either command.


## Identify columns or rows with Missing values

`is.na()` is the base R way to identify, in a TRUE/FALSE manner, whether or not there are missing values in a vector

```{r}
y <- c(1,2,3,NA)

is.na(y) # returns a vector (F F F T)
```

## Find the percentage of a variable that is missing

Sometimes necessary to check before conducting an analysis. *This requires my package*, `legaldmlab`

```{r}
?legaldmlab::count_missing

cars %>% 
  select(hp:drat) %>% 
  legaldmlab::count_missing()
```



## Exclude Missing values from analysis



# Dropping Missing values from the data set

`tidyr::drop_na()`


<!--chapter:end:04-clean.Rmd-->

# Working with Factors

<!--chapter:end:05-factors.Rmd-->

# Working with Strings

<!--chapter:end:06-strings.Rmd-->

# Figures and Graphs

## Use different fonts

See tutorial on [this web page](https://www-r--bloggers-com.cdn.ampproject.org/v/s/www.r-bloggers.com/2021/07/using-different-fonts-with-ggplot2/amp/?amp_gsa=1&amp_js_v=a6&usqp=mq331AQIKAGwASCAAgM%3D#amp_tf=From%20%251%24s&aoh=16259111950507&csi=0&referrer=https%3A%2F%2Fwww.google.com&ampshare=https%3A%2F%2Fwww.r-bloggers.com%2F2021%2F07%2Fusing-different-fonts-with-ggplot2%2F)

<!--chapter:end:07-ggplot.Rmd-->

# Tables

<!--chapter:end:08-tables.Rmd-->

# Misc. Stuff

## Scrape web pages for data tables

```{r}

#### Example 1 ####
library(rvest)
library(tidyverse)

html=read_html('https://shop.tcgplayer.com/price-guide/pokemon/base-set') %>% 
  html_table(fill = TRUE)

html

html=as_tibble(html[[1]] %>% select('PRODUCT','Rarity','Number','Market Price'))

html

# remove $ symbol in Price column to make it easier to work with
gsub('\\$','',html$`Market Price`) #(what you're looking for, replace with, from where)
html$`Market Price`= gsub('\\$','',html$`Market Price`)
html$`Market Price`=as.numeric(html$`Market Price`)


#### Example 2 ####
html1=read_html("https://scores.nbcsports.com/golf/averages.asp?tour=LPGA&rank=04") %>% 
  html_table(fill = TRUE)

html2=read_html("https://scores.nbcsports.com/golf/averages.asp?tour=LPGA&rank=08") %>% 
  html_table(fill = TRUE)

html3=read_html("https://scores.nbcsports.com/golf/averages.asp?tour=LPGA&rank=06") %>% 
  html_table(fill = TRUE)

html4=read_html("https://scores.nbcsports.com/golf/averages.asp?tour=LPGA&rank=12") %>% 
  html_table(fill = TRUE)

lpga_drivingstats=as.tibble(html1[[2]])
lpga_puttavgs=as.tibble(html2[[2]])
lpga_greensinreg=as.tibble(html3[[2]])
lpga_avgscore=as.tibble(html4[[2]])

lpga_avgscore= lpga_avgscore%>%slice(2:nrow(lpga_avgscore))
fix(lpga_avgscore)

fix(lpga_puttavgs)
lpga_puttavgs=lpga_puttavgs%>%select(-(X4))%>%slice(2:nrow(lpga_puttavgs))

fix(lpga_drivingstats)
lpga_drivingstats=lpga_drivingstats%>%slice(2:nrow(lpga_drivingstats))

fix(lpga_greensinreg)
lpga_greensinreg=lpga_greensinreg%>%slice(2:nrow(lpga_greensinreg))

lpga_drivingstats%>%select(-(Rank))%>%left_join(lpga_greensinreg,by="Name")

lpga_avgscore=lpga_avgscore%>%select(-(Rank))
lpga_drivingstats=lpga_drivingstats%>%select(-(Rank))
lpga_puttavgs=lpga_puttavgs%>%select(-(Rank))
lpga_greensinreg=lpga_greensinreg%>%select(-(Rank))

lpga_avgscore=lpga_avgscore%>%full_join(lpga_drivingstats,by="Name")
lpga_avgscore=lpga_avgscore%>%left_join(lpga_greensinreg,by="Name")
lpga_avgscore=lpga_avgscore%>%left_join(lpga_puttavgs,by="Name")
lpga=as.tibble(lpga_avgscore)
```


<!--chapter:end:09-misc.Rmd-->

# Introduction to Functions and Loops

<!--chapter:end:10-functions.Rmd-->

# Intro to R Markdown

<!--chapter:end:11-markdown.Rmd-->

# Statistics Stuff

<!--chapter:end:12-stats.Rmd-->

