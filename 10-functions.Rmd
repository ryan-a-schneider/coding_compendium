# Intermediate R: Functions, Loops, and Iterative Programming

## Functions

A function is a command that performs a specified operation and returns an output in accordance with that operation. You can literally make a function to do anything you want.

*General structure of a basic function:*

```{r chapter_10, eval=FALSE}
# example structure

Function_name=function(argument){
  Expressions
  return(output)
}
```

- *Argument* is your input. It is the thing you want to perform the operation on.
- *Expressions* is the actual operation (or operations) you want to perform on the supplied argument
- *return* tells R to return the result of the Expression to you when done.

This example function takes an input of numbers in the form of a vector and subtracts two from each.

```{r 10.2}
numbers=c(2,10,12,80)

sub_2=function(x){
  result= x - 2
  return(result)
}

sub_2(numbers)

sub_2(100)
```

One of the primary advantages of functions are that they can reduce a complex process or a process that involves many steps down into a single line of code; thus, creating your own functions is a fast way to make your life easier down the line either at some point in the far future or even in just a few minutes, if you know you will be writing the code for some process two or more times.

Take this script for instance. You can see from the circled parts that I needed to transform three different data sets in a similar way:

```{r}
knitr::include_graphics(here::here("pics", "repeat_process.jpg"))
```

Copying and pasting the code and tweaking it originally worked....but this method can make the script needlessly long and harder to read later, and more tedious to write or for coauthors/collaborators to sift through, and importantly, increases your chances of making an error. Better to write a single function that could be applied to all three....

***In short, use functions to reduce a multi-step process or a process that you're implementing >=2 times in a single script into one command. This saves you space and makes the script shorter; it saves you the trouble and effort of re-writing or adapting code from earlier sections; and importantly, reduces the chances of you making a coding error by proxy of the former two.*** As a quick example, I replaced each of the circled paragraphs of code above with a custom function that ran everything in one simple line. Instead of 3 paragraphs, I now had 3 lines that looked like this:

```{r eval=FALSE}
na_zero_helpreint=rotate_data(data = na_zero_helpreint, variable_prefix = "reintegrate_")
na_blank=rotate_data(data = na_zero_helpreint, variable_prefix = "barrier_")
na_zero=rotate_data(data = na_zero_helpreint, variable_prefix = "barrier_")
```



### Limitations to your average, everyday functions
While reducing a whole *process or sequence* of commands is extremely useful, it still leaves a limitation. For instance, while we avoided copying and pasting whole paragraphs or processes, I still had to copy-paste the same function three times. This still leaves chances for error on the table, and it still leaves us with wasted lines that make the script longer.

In general, when you want to perform some function or process **multiple times on multiple items (as above where the same command is used three times on three different data frames)**, you need to use a for-loop or iterating function. These can reduce further unwanted redundancies by applying the function or process iteratively. Read on for more info.


## For-loops

A for loop is essentially  a function that applies a function or given set of operations to multiple things at once, and returns an output of many items.

For example, this code finds the means of every vector/column in a dataset by repeatedly applying the same code over and over to element "i" in the given list:

```{r 10.3}
df <- tibble(
  a = rnorm(10),
  b = rnorm(10),
  c = rnorm(10),
  d = rnorm(10)
)

output <- vector("double", ncol(df))  # 1.Output. Create the object you want the results of the loop stored in.

for (i in seq_along(df)) {            # 2.Sequence of operations. "For each item 'i' along data frameâ€¦"
  output[[i]] <- median(df[[i]])      # 3.Body:"every individual item in 'output' = the median of each col in df
}

output
```

Check out [this book chapter](https://r4ds.had.co.nz/iteration.html#mapping-over-multiple-arguments) for a great and detailed explanation of for-loops and functional coding.

Although for loops are nice, they are unwieldy. R programmers typically use iterating functions instead. Examples of iterating functions are the lapply, vapply, sapply, etc. family of base R commands. But these can also be confusing and the commands are not great.

The purrr package offers a better way to do iterating functions over base R; it's the tidyverse way to make efficient and understandable for loops! **If you have a need for a for-loop for something, see the next section instead on how to use purrr to make an iterative function. Important to understand conceptually what a for-loop is, but using them is impractical when you have purrr**


## purrr and Iterative Functions

*All notes here come from Charlotte Wickham's lecture tutorial below*

Part 1: https://www.youtube.com/watch?v=7UlWJWfZO9M
Part 2: https://www.youtube.com/watch?v=b0ozKTUho0A&t=1210s

purrr's map functions offer a way to apply any existing function (even functions you've made) to multiple things at once (be it lists; data frame columns, individual items in vector, etc.).

When you have tasks that you want to do repeatedly, you can either copy and paste your code a bunch of times, or make an iterative function that does each task for you. You could use a for-loop to do these tasks, but {purrr} is a package that lets you build iterating functions, which have advantages over for-loops.

For example, instead of copy-pasting the above function `rotate_data` and having it repeated three times in our script, we can use `purrr::map()` to apply that function iteratively to each data frame in a list. The result....

```{r eval=FALSE}
dfs=list(na_blank=na_blank, na_zero=na_zero) %>% 
  map(.f=rotate_data, variable_prefix = "barrier")
```

...is now a single line of code where once we had three. Instead of applying the same function three times to each data frame separately, `map` applies it to each in turn with one command.

## How to use purrr

```{r purrr_pic}
knitr::include_graphics(here::here("pics", "purrr.png"))
```

The structure of `map()` commands is the same as the others in the tidyverse:
```{r eval=FALSE}
#option 1
map(data, function)

# option 2
data %>% map(function)
```

```{r}
knitr::include_graphics(here::here("pics", "map_structure.png"))
```

*map() commands work like this:* For each element of x, do f.

So if you pass it object x and object x is....
- A vector, it will perform function f on every item in the vector
- A data frame, it will perform function f on every *column* in the data frame
- A list, it will perform function f on every *level in the list*

Etc., etc.; the point is it applies a function repeatedly to every element in the object you supply it with.
Or in English: *"For each element of x, apply f"*
```{r}
knitr::include_graphics(here::here("pics", "map_structure_2.png"))
```



**NOTE that when you include additional arguments in a map call, you do not include extra parantases. 











#### Apply a single function to every column in a data frame

Pipe the whole data frame to the map command:
```{r 10.4, eval=FALSE}
df %>% map_df()
```


#### Apply a function to every item in a column/vector
Pipe the data frame and column/variable, and include the [ ] to index by vector position:
```{r 10.5, eval=FALSE}
BF_output$Evidence= BF_output$BF[] %>% map_chr(effectsize::interpret_bf)
```


#### Import several files in a directory at once (batch importing)

**Note.** This reads many .csv files into a SINGLE, unified data frame.
If you want to import many files at once but keep them separated, you'll need a different command

```{r 10.6, eval=FALSE}
file_path <- "JLWOP/Data and Models/"

# view all files
file_path %>% list.files()

# save only file names with the desired extension
csv_file_names=file_path %>% 
  list.files() %>% 
  .[str_detect(., ".csv")]


# Load everything into the Global Environment
csv_file_names %>%
  purrr::map(function(file_name){ # iterate through each file name
    assign(x = str_remove(file_name, ".csv"), # Remove file extension ".csv"
           value = read_csv(paste0(file_path, file_name)),
           envir = .GlobalEnv)
  })
```

All of the above can be combined into a single function:

```{r 10.7, eval=FALSE}
read_all_excel=function(path){
  file_path <- path
  
  # save only file names with the desired extension
  file_names=file_path %>% 
    list.files() %>% 
    .[str_detect(., ".xlsx")]
  
  file_names %>%
    purrr::map(function(file_name){ # iterate through each file name
      assign(x = str_remove(file_name, ".xlsx"), # Remove file extension ".csv"
             value = readxl::read_excel(paste0(file_path, file_name)),
             envir = .GlobalEnv)
    })
}

read_all_excel(path = "JLWOP/Data and Models/")
```


### Walkthrough Case Example

This is an example walk through showing how we can use `purrr` to speed things up dramatically and/or reduce the use of unwanted, extra code in our scripts. In this guide I'll be building a table of LPGA Tour statistics from multiple webpages.

If I tried to do each table individually, I'd be copying and pasting and re-writing the same code up to **four times** to get each table downloaded, extracted, and formatted the way I want before I could unify them with `left_join`. By using `purrr::map()`, we can cut our needed code down by 75%.

Not only does this mean we have a tidier script, but also, things will be less messy, and we have less chances for error (since we are coding less). And of course, we don't have the annoyances of redoing multiple sections of code.

```{r 10.8, include=FALSE, echo=FALSE}
pacman::p_load(rvest, tidyverse)
```

The workflow for purrr goes like this:

First, you want to figure out how to do each step of your process line-by-line, for a single item. The idea is to try and walk through each step of the process and see exactly what will need to be done each each step and what the code will like, *before trying to code it all at once at a higher level*.

Once you have each step for the first item figured out, make functions for each step that condense that code down to one command.

Lastly, apply each function from your individual steps to all items in your list by using `purr::map()`.


### Do for One

#### 1. Scrape data

```{r 10.9}
# line
html1=read_html("https://scores.nbcsports.com/golf/averages.asp?tour=LPGA&rank=04") %>% 
  html_table(fill = TRUE)


# function
quick_read_html=function(url){
  url=url %>% read_html(url) %>%
    html_table(fill = TRUE) 
}

html=quick_read_html("https://scores.nbcsports.com/golf/averages.asp?tour=LPGA&rank=04")
```


#### 2. Find out which element of the list the desired table is in

```{r 10.10}
head(as_tibble(html1[[2]]))
```

#### 3. Extract the table

```{r 10.11}
#line
table1=as_tibble(html1[[2]])


# function version
extract_tibble=function(html_list){
  df=as_tibble(html_list[[2]])
  return(df)
}

table1=extract_tibble(html1)
```


#### 4. Format table

```{r 10.12}
#line
table1=table1 %>% 
  select(-X1) %>% 
  rename("Name"="X2") %>% 
  slice(2:n())

head(table1)


# function
test_format=function(table){
  table=table %>% 
    select(-X1) %>% 
    rename("Name"="X2") %>% 
    slice(2:n())
  
  return(table)
}

# test_format(table1)
```

### DO FOR ALL

```{r 10.13}

#### FUNCTIONS ####
# Read
quick_read_html=function(url){
  url=url %>% read_html(url) %>%
    html_table(fill = TRUE) 
}

# Extract
extract_tibble=function(html_list){
  df=as_tibble(html_list[[2]])
  return(df)
}

# Format
test_format=function(table){
  table=table %>% 
    select(-X1) %>% 
    rename("Name"="X2") %>% 
    slice(2:n())
  
  return(table)
}

#### GO FOR IT ####

URLs=c("https://scores.nbcsports.com/golf/averages.asp?tour=LPGA&rank=04",
       "https://scores.nbcsports.com/golf/averages.asp?tour=LPGA&rank=08",
       "https://scores.nbcsports.com/golf/averages.asp?tour=LPGA&rank=06",
       "https://scores.nbcsports.com/golf/averages.asp?tour=LPGA&rank=12")


tables_list=URLs %>% 
  map(quick_read_html) %>% #read and scrape every URL
  map(extract_tibble) %>% # Get rid of the extra list levels
  map(test_format) # Apply any formatting that would be universal to all of them at once


lpga_data= tables_list %>% 
  reduce(left_join, by="Name") %>% # Combine all list levels into a single tibble, matching by the "Name" column
  rename("Avg_Drive"="X3.x", "Avg_Putts"="X3.y", # final, non-universal formatting
         "Rounds_Played"="X3.y.y" , "Avg_Score"="X4", 
         "Greens_Hit"="X3.x.x")

# VOILA! 
head(lpga_data)

```
