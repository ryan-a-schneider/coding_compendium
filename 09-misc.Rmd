# Misc. Stuff

## Scrape web pages for data tables

See Chapter 10's example `purrr` walk through for a guide on how to scrape multiple web tables simultaneously 

***Simple example***

```{r}
library(rvest)
library(tidyverse)

html=read_html('https://shop.tcgplayer.com/price-guide/pokemon/base-set') %>% 
  html_table(fill = TRUE)

html

# Saved as a list by default. Now extract your table from said list
html=as_tibble(html[[1]] %>% # find out which number it is in the list
                 select('PRODUCT','Rarity','Number','Market Price')) # if needed, specify which columns you want too

html

# remove $ symbol in Price column to make it easier to work with
html$`Market Price`=str_remove(html$`Market Price`, pattern = "\\$")
  
html=html %>%  mutate(`Market Price`=as.numeric(`Market Price`)) # convert from string to numeric

# view finished table
head(html)
```

***Slightly more complicated example***



```{r}
pacman::p_load(rvest, tidyverse)

exonerations_table=read_html("https://www.law.umich.edu/special/exoneration/Pages/detaillist.aspx") %>% 
  html_nodes("table.ms-listviewtable") %>% 
  html_table(fill=TRUE, header = TRUE)
```

From here you now need to clean up the table

```{r}
exonerations_table=as.data.frame(exonerations_table)

table_names=exonerations_table$Last.Name[1:20] # copy the column names into a vector before deleting them

exonerations_table=exonerations_table %>% 
  select(Last.Name:Tags.1) %>% # get rid of extra columns
  slice(22:n()) # get rid of extra rows

colnames(exonerations_table)=table_names # over-write the current column names with the vector of names we created

glimpse(exonerations_table) # data is a bit messed up. All columns are chr, and some values not recognized as missing

# wrangle to fix
exonerations_table=as_tibble(exonerations_table) %>% 
  janitor::clean_names() %>% 
  na_if("") %>% 
  mutate(dna=if_else(dna=="DNA",1,0),
         mwid=if_else(mwid=="MWID",1,0),
         fc=if_else(fc=="FC",1,0),
         p_fa=if_else(p_fa=="P/FA",1,0),
         f_mfe=if_else(f_mfe=="F/MFE",1,0)) %>% 
  replace_na(dna:f_mfe, 0) %>% 
  mutate(across(c(dna:f_mfe),factor))

exonerations_table # done!
```


Check out [this page](https://www.dataquest.io/blog/web-scraping-in-r-rvest/) for a quick overview.



```{r}
exonerations_table=as.data.frame(exonerations_table)

table_names=exonerations_table$Last.Name[1:20]

exonerations_table=exonerations_table %>% 
  select(Last.Name:Tags.1) %>% 
  slice(22:n())

colnames(exonerations_table)=table_names

exonerations_table=exonerations_table %>% janitor::clean_names()
```


## Read SPSS files into R

Use `foreign::read.spss`

```{r eval=FALSE}
spss_version=foreign::read.spss(here::here("JLWOP", "Data and Models", "JLWOP_RYAN.sav"), to.data.frame = TRUE)
```

Might also want to add `as_tibble()` on the end.

## Turn numbers into percentages

Use `scales::percent()`, which converts normal numbers into percentages and includes the percent sign (%) afterwards

```{r}

mutate(Percent_in_ROPE=scales::percent(ROPE_Percentage,accuracy = 0.1, scale = 100))
```

Scale is what to multiple the original number by (e.g., convert 0.05 to 5% by x100)
Accuracy controls how many places out the decimal goes

## Find all possible combindations of items in a vector

```{r}
y <- c(2,4,6,8)

combn(c(2,4,6,8),2) # find all possible combinations of these numbers, drawn two at a time
```

## Download files from the internet

```{r}
download.file(url, destfile, method, quiet = FALSE, mode = "w",
              cacheOK = TRUE,
              extra = getOption("download.file.extra"),
              headers = NULL, ...)
```


## Print multiple things in one statement

Use `cat()` from base R

```{r}
cat("The p-value dropped below 0.05 for the first time as sample size", 100)
```

