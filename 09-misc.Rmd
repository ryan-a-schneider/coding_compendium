# Misc. Stuff

## Scrape web pages for data tables

See Chapter 10's example `purrr` walk through for a guide on how to scrape multiple web tables simultaneously 

***Simple example***

```{r}
library(rvest)
library(tidyverse)

html=read_html('https://shop.tcgplayer.com/price-guide/pokemon/base-set') %>% 
  html_table(fill = TRUE)

html

# Saved as a list by default. Now extract your table from said list
html=as_tibble(html[[1]] %>% # find out which number it is in the list
                 select('PRODUCT','Rarity','Number','Market Price')) # if needed, specify which columns you want too

html

# remove $ symbol in Price column to make it easier to work with
html$`Market Price`=str_remove(html$`Market Price`, pattern = "\\$")
  
html=html %>%  mutate(`Market Price`=as.numeric(`Market Price`)) # convert from string to numeric

# view finished table
head(html)
```

***Slightly more complicated example***



```{r}
pacman::p_load(rvest, tidyverse)

exonerations_table=read_html("https://www.law.umich.edu/special/exoneration/Pages/detaillist.aspx") %>% 
  html_nodes("table.ms-listviewtable") %>% 
  html_table(fill=TRUE, header = TRUE)
```

From here you now need to clean up the table

```{r}

exonerations_table=as.data.frame(exonerations_table) # turn into a df

# save the names to a vector
table_names=exonerations_table$Last.Name[1:20]

# Trim out the garbage rows and columns
exonerations_table=exonerations_table %>% 
  select(Last.Name:Tags.1) %>% 
  slice(22:n())

# over-write incorrect col names with the vector of correct ones we saved above
colnames(exonerations_table)=table_names

# clean up names
exonerations_table=exonerations_table %>% janitor::clean_names()

# check structure of columns
glimpse(exonerations_table)


exonerations_table=as_tibble(exonerations_table) %>% # convert to tibble
  mutate(across(c(dna,mwid:ild), na_if,"")) %>% # turn missing values into NA's
  mutate(across(c(dna,mwid:ild), replace_na, "derp")) %>% # replace NA's with a some string (needed for the next lines to work)
  mutate(dna=ifelse(dna=="DNA",1,0), # change these variables from text to numeric to better facilitate analysis
         mwid=ifelse(mwid=="MWID",1,0),
         fc=ifelse(fc=="FC",1,0),
         p_fa=ifelse(p_fa=="P/FA",1,0),
         f_mfe=ifelse(f_mfe=="F/MFE",1,0)) %>% 
  mutate(across(c(state, crime, dna:f_mfe),factor)) # correct form by converting to factors

exonerations_table
```


Check out [this page](https://www.dataquest.io/blog/web-scraping-in-r-rvest/) for a quick overview.



```{r}
exonerations_table=as.data.frame(exonerations_table)

table_names=exonerations_table$Last.Name[1:20]

exonerations_table=exonerations_table %>% 
  select(Last.Name:Tags.1) %>% 
  slice(22:n())

colnames(exonerations_table)=table_names

exonerations_table=exonerations_table %>% janitor::clean_names()
```


## Read SPSS files into R

Use `foreign::read.spss`

```{r eval=FALSE}
spss_version=foreign::read.spss(here::here("JLWOP", "Data and Models", "JLWOP_RYAN.sav"), to.data.frame = TRUE)
```

Might also want to add `as_tibble()` on the end.

## Turn numbers into percentages

Use `scales::percent()`, which converts normal numbers into percentages and includes the percent sign (%) afterwards

```{r}

mutate(Percent_in_ROPE=scales::percent(ROPE_Percentage,accuracy = 0.1, scale = 100))
```

Scale is what to multiple the original number by (e.g., convert 0.05 to 5% by x100)
Accuracy controls how many places out the decimal goes

## Find all possible combindations of items in a vector

```{r}
y <- c(2,4,6,8)

combn(c(2,4,6,8),2) # find all possible combinations of these numbers, drawn two at a time
```

## Download files from the internet

```{r}
download.file(url, destfile, method, quiet = FALSE, mode = "w",
              cacheOK = TRUE,
              extra = getOption("download.file.extra"),
              headers = NULL, ...)
```


## Print multiple things in one statement

Use `cat()` from base R

```{r}
cat("The p-value dropped below 0.05 for the first time as sample size", 100)
```

