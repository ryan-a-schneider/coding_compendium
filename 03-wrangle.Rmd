# Wrangle Data

This chapter contains useful tips on wrangling (i.e., manipulating) data. If you need to know to do to things like create new variables, split one variable into multiple variables, pivot a data set from wide to long, etc., look no further.

If you want a pretty good intro tutorial to the `dplyr` package, click [here](https://www-r--bloggers-com.cdn.ampproject.org/v/s/www.r-bloggers.com/2021/01/how-to-analyze-data-with-r-a-complete-beginner-guide-to-dplyr/amp/?amp_js_v=a6&gsa=1&usqp=mq331AQFKAGwASA%3D#csi=0&referrer=https%3A%2F%2Fwww.google.com&tf=From%20%251%24s&ampshare=https%3A%2F%2Fwww.r-bloggers.com%2F2021%2F01%2Fhow-to-analyze-data-with-r-a-complete-beginner-guide-to-dplyr%2F)

## Joining or Splitting

Joining and splitting data is pretty straightforward....

### Whole Data Sets

The code below is from [this excellent tutorial](https://www.youtube.com/watch?v=SCdmyyoudb8&t=23s)

```{r chapter_3}
set.seed(2018)

df1=data.frame(customer_id=c(1:10),
               product=sample(c('toaster','TV','Dishwasher'),10,replace = TRUE))


df2=data.frame(customer_id=c(sample(df1$customer_id, 5)),state=sample(c('New York','California'),5,replace = TRUE))

df1=tibble::as_tibble(df1)
df2=tibble::as_tibble(df2)

# df1 =left table
# df2= right table
```

Inner join - retains only rows with values that appear in both tables, and matches by keys.

*If you're joining two Qualtrics surveys together, this is most likely the one you want to use (e.g. matching by participant name, and only keeping rows in the joined data set for participants that have responses logged in both survey 1 and survey 2*
```{r 3.2}
df1 %>% inner_join(df2,by='customer_id')
```

Left join - returns everything in the left, and rows with matching keys in the right
```{r 3.3}
df1 %>% left_join(df2,by='customer_id')
```

Right join - returns everything in the right, and rows with matching keys in the left
```{r 3.4}
df1 %>% right_join(df2,by='customer_id')

# note: example if the customer id column was named something different in the second df
    #df1 %>% left_join(df2,by=c('customer_id'='name2'))
```

Full join - retain all rows from both tables, and join matching keys in both right and left
```{r 3.5}
df1 %>% full_join(df2,by='customer_id')
```

Anti join - returns all rows in the left that do not have matching keys in the right
```{r 3.6}
df1 %>% anti_join(df2,by='customer_id')
```


### Individual Columns/Variables

Splitting or joining columns is much easier than doing it to whole data sets. You can use `dplyr::separate()` to accomplish the former, and `dplyr::unite()` for the latter.

```{r 3.7}
print("hello")
```


## Selecting/extracting specific variables

Sometimes when working with a data set, you want to work with a few *specific* variables. For instance, maybe you want to view a graph of only reverse-coded variables (which start with the prefix "r"); or maybe you want to create a subset of your data that has a few specific variables removed. For this you can use `dplyr::select()` and its associated helper commands

`select()` can be thought of as "extract"; it tells R to identify and "extract" a specific variable (or variables)


```{r 3.8, eval=FALSE}
cars=mtcars

# select one column
cars %>% select(mpg)

# select multiple columns, if they are all next to one another
cars %>% select(mpg:hp)

# select multiple columns by name (when not next to one another) by defining them in a vector
cars %>% select(c(mpg, hp, wt))

# select only variables that start with a certain prefix/character/pattern/etc.
cars %>% select(starts_with("d"))

# ...or columns that end with a certain prefix/etc.
cars %>% select(ends_with("t"))

# ...or contains a certain pattern or string
cars %>% select(contains("se"))

# select ALL OF the variables in a data set that match those of a pre-defined vector
  
  # first define the names in a vector
  vars=c("hp", "drat", "gear", "carb")
  
  #now use helper
  cars %>% select(all_of(vars))
  
# select ANY OF the variables in a pre-defined vector
  
  vars_2=c("hp", "drat", "watermelon", "grilled_cheese") # only the first two will be in the data
  
  cars %>% select(any_of(vars_2)) # only (and all of) the variables actually PRESENT in the data are pulled
  
# select only variables of a certain class or type
  cars %>% select(where(is.numeric))
  cars %>% select(where(is.character))
```


Other examples can be seen on [THIS LINK](https://tidyselect.r-lib.org/reference/language.html) for a simple but detailed guide.



## If-then and Case-when

### If-then
The premise of an if/then or if/else statement is simple: "If condition 1 is satisfied, perform x operation; if not, then do y"

```{r 3.9}
mtcars %>% mutate(power_level=ifelse(mtcars$hp<350, "Low", "High")) %>% head()
```
This line of code effectively says: if the length in Sepal.Length is >5, set new variable = to "short"; else, set it to "long"


### Case-when

When you have 3+ conditions, it's easier to use case-when. This is a more simple and straightforward approach than nesting multiple if-else commands

```{r 3.10, eval=FALSE}
My_vector= case_when(
	Condition1 ~ value1,
	Condition2 ~ value2,
	Condition3 ~ value3
	TRUE ~ valueForEverythingElse #catch all for things that don't meet the above conditions
	)
```

Example:
```{r 3.11}

mtcars %>% mutate(size= case_when(cyl==4 ~ "small",
                                  cyl==6 ~ "medium",
                                  cyl==8 ~ "large")) %>% 
  select(c(cyl,size)) %>% head()
```

## Conditional replacement of values

The following code is useful if you want to replace a value in one column, and the replacement is conditional upon the value in another column.

```{r 3.12}
mpg %>% 
  mutate(across(.cols = c(displ, cty, hwy),
                .fns = ~case_when(cyl == 4L ~ as.numeric(NA),
                                  TRUE ~ as.numeric(.x))))
```


```{r 3.13, eval=FALSE}
test %>% 
  mutate(across(.cols = c(rank),
                .fns = ~case_when(is.na(participant_score) ~ as.numeric(NA),
                                  TRUE ~ as.numeric(.x))))
```



## Merging variables

Sometimes you'll have multiple variables and you want to collapse them into a single variable. The `pmin()` command is useful for this.

```{r3.14}
example_data=tribble(~A,~B,~C,
                     1,NA,NA,
                     2,NA,NA,
                     3,NA,NA,
                     NA,4,NA,
                     NA,5,NA,
                     NA,6,NA,
                     NA,NA,7,
                     NA,NA,8,
                     NA,NA,9)

example_data %>%
  mutate(accept_reject = 
           pmin(A,B,C,na.rm = TRUE))
```



## Apply a function to multiple variables at once

You can either specify each column individually, like above, or tell R to identify columns for you based on their type or their name. This requires adding in one additional verb--either contains() or where() depending on what you want to do.

Two simple examples:

```{r 3.15}
# turn multiple variables into factors
ex_data=dplyr::tribble(~color, ~car,
                       "red", "corvette",
                       "blue", "chevelle",
                       "green", "camaro",
                       "red", "corvette",
                       "green", "chevelle",
                       "yellow", "gto")

dplyr::glimpse(ex_data)

ex_data %>% mutate(across(c(color, car),factor))

# round multiple columns to 1 decimal place
mtcars %>% mutate(across(c(disp:qsec),round,1)) %>% head()
```


## Pivoting (i.e., transposing) data

### Condense multiple rows into a single column (pivot wide to long)

Rearranging data like this can make it easier to work with and analyze. Example below from my gradebook for stats (exported from Canvas), with fake names. 

The command structure is as follows:

```{r 3.16, eval=FALSE}

 pivot_longer( # Transpose LENGTHWISE by....
    cols = everything(), # Taking ALL variable names...
    names_to="variable", # ...and dumping them into this new variable/column
    values_to="missing_count") #...and placing their values in this other new column
```

**NOTE!!!** Pivoting data from wide to long like this expands the number of rows to make a matrix so that (for example, each student now has as a row for each assignment). Therefore, you can only pivot longways (or wide) **ONCE**, otherwise you will make duplicates. 

*If you need to pivot multiple columns, just include all of the columns in one single pivot; do not use two separate, back to back pivot commands.*

Example:

```{r 3.17}
gradebook=tibble::tribble(
  ~Student, ~Homework.1, ~Homework.2, ~Homework.3, ~Homework.4, ~Homework.5, ~Quiz.1, ~Quiz.2, ~Quiz.3, ~Quiz.4, ~Final,
     "Bob",         19L,          0L,          13,          16,          0L,      21,      7L,      15,    17.5,     33,
    "Jane",         17L,         19L,          16,        16.5,         25L,    21.5,     19L,   14.75,     9.5,   39.5,
    "John",         19L,         19L,        14.5,        19.5,         25L,      21,     21L,    18.5,      17,   46.5
  )

head(gradebook)

gradebook=gradebook %>% 
   pivot_longer( # Transpose lengthwise by:
    cols = Homework.1:Final, # Taking these variables
    names_to="Assignment", # ...and dumping them into this new variable, storing them lengthwise
    values_to="Points") #...then place their values in this new column

gradebook %>% head()
```


## Managing Many Models

Imagine the concept of Russian Dolls, applied to data sets. You can manage data sets more effectively my collapsing them into a single tiny, mini data frame, and stuffing that inside of another one.

This is done via "nesting"...

Effectively, you smush/collapse everything down so it fits inside one column. You can unnest to expand this data back out later when you need it, and keep it collapsed when you don't. Code works like this:

```{r 3.18, eval=FALSE}
by_country=gapminder::gapminder %>% 
  group_by(continent,country) %>% # indicate the variables to keep at the top level
  nest() # smush the rest into a list-column


country_model=function(df){
  lm(lifExp~year1950,data = df)
}

# Transform a list of models into a df
models=by_country %>% 
  mutate(mod=map(data,country_model))
```

- You can store anything in a data frame. You can keep the df connected to the model, which makes it very easy to manage a whole slew of related models
- You can use functional programming (i.e., iterative functions) to map functions or combinations of functions in new ways.
- Converting data into tidy data sets gives you a whole new way (and easier way) to manage lots of information

Below is the full script I copied from Hadley Wickham's lecture, which you can watch [here](https://www.youtube.com/watch?v=rz3_FDVt9eg)

```{r eval=FALSE}

pacman::p_load(dplyr,purrr,tidyverse,gapminder)

#### Workflow for managing many models in R ####
# 1. Nest data with {tidyr}
# 2. Use {purrr} to map a modeling function
# 3. Use {broom} to inspect your tidy data


gapminder=gapminder %>% 
  mutate(year1950= year-1950) #the number of years it's been since 1950

#--------------------------------------------------------------------------------------------
#### Step 1. Nest the data. ####

# A nested data frame has one column per country. You're essentially 
# creating a Russian doll; a data frame inside of a larger data frame.

by_country=gapminder %>% 
  group_by(continent,country) %>% # variables to keep at the top level
  nest() # smush everything else into a df, and store this mini-df in its own column

# with this, you can have an entire table per row; a whole data frame for each country
# Essentially condensing a list into a table
by_country$data[[1]]


#--------------------------------------------------------------------------------------------

#### Step 2. Use purrr to map stuff. ####

# 12:50
country_model=function(df){
  lm(lifeExp ~ year1950, data = df)
}

models= by_country %>% 
  mutate(
    mod=map(data,country_model)
  )


gapminder %>% 
  group_by(continent,country) %>% 
  nest() %>% 
  mutate(
    mod= data %>% map(country_model)
  )

# 27:11

#--------------------------------------------------------------------------------------------
##### Step 3. ####

# This creates another nested df inside of your main data frame that has the summary stats of each model
models=models %>% mutate(
  tidy=map(mod, broom::tidy), # tidy() gives model estimates
  glance=map(mod,broom::glance), # glance() gives model summaries
  augment=map(mod,broom::augment) # model coefficients
)

# What can you do with this nest of data frames? 
# The reverse of step 1; un-nest it to unpack everything!
# 34:40
# Keeps a massive list of related information neatly organized!

unnest(models,data) # back to where we started
unnest(models,glance, .drop = TRUE) 
unnest(models,tidy) 
```

...and here is a version I made of the above to manage many Bayesian models. Admittedly, I'm not really sure how useful this is though.

```{r eval=FALSE}
# CONDENSED MASTER TABLE VERSION -----------------------------------------------------------------------------
# Models table that has all models condensed

models=tribble(~Model_name, ~model_descrip, ~model,
               "Thesis_Model", "Discount and PTS", Thesis_Model,
               "discount_model", "Discount variable only", discount_model,
               "PTS_model", "PTS variable only", PTS_model
)

# Clean up work space
#rm(DiscountPrior,Priors_MEmodel,Priors_Interactionmodel)

# Grab and store all model info 
models=models %>% 
  mutate(prior_info=map(model,describe_prior),
         posterior_info=map(model, describe_posterior_fancy),
         model_performance=map(model,performance::performance)
         
  )

# DO NOT TRY AND VIEW THE TABLE IN A WINDOW!!!! RStan objects are so large they cause R to lock up
# Call the model in the console instead

#### summon individual model stats ####
describe_prior(models$model[[1]]) #by specific model
map(models$model,describe_prior) # do for all models at once

# or all info for all models at once
unnest(models,posterior_info) %>% 
  select(-c(model,prior_info,model_descrip))
```


## Turn row names into a column/variable

Use the `rownames()` command to turn row names into a variable

```{r}
cars=rownames_to_column(mtcars, var = "car")

as_tibble(cars) %>% slice(1:6)
```

## How to edit/change column names

TWO WAYS TO DO THIS: Use `colnames()` (for base R) or `rename()` (for tidyverse)

`colnames()` pulls up all the column/variable names as a vector. If you want to actually change them, you'll need to combine this command with something like the sub() or gsub() commands (for base R). I'm going to skip this because...its base R.

To access and change the names faster via tidyverse, run use `rename()`
```{r}
rm(list=ls()) # clear R's memory

iris %>% rename("hurr"="Sepal.Length",
                "durr"="Sepal.Width",
                "abcdefgh"="Species") %>% 
  head()
```


If you need to do some really fancy conditional renaming (e.g., changing all variables that start with "r" to start with "rf" instead, to make it more clear that the prefix actually stands for "risk factor" rather than "reverse coded"), you'll need to use `rename_with()`. 

This command has two parts to it: the data set, and the function you wish to apply to it (which you put after the `~`)

```{r }
rename_with(iris, ~ gsub(pattern = ".", replacement = "_", .x, fixed = TRUE)) %>% 
  head()
```

The gsub() function from Base R identifies matching patterns in the data and substitutes them with what you want instead. Think of it like R's version of Find/Replace from Microsoft Word.

The above line of code thus does the following:
	1. First, it checks the column names of the supplied data set (`iris`) for a specific pattern (specified in `pattern=` )
	2. Then it replaces that pattern with your input in `replacement=`

The great thing about rename_with() is that the .fn (or `~` for short) can take *ANY* function as input. For example, if you want to **add** an element to the column names rather than replace something, (e.g., a prefix or suffix), you can change the function to:

```{r}
rename_with( iris, ~ paste0(.x,  "_text")) %>% 
  head()
```

The above line adds a suffix. You can also add a prefix in the exact same way, just by switching the order of the string and the pattern in the paste0 command.


***Alternative method to the above***
This is a second way to do the above. It may appear more simple, but it's also probably not as theoretically consistent with how the packages were made…..it uses the `stringr` package to rename the column names, and `stringr` is typically used for editing vectors of strings in a data set.

…so it works, but it's a little unconventional because you call and edit the column names like you would a variable in your data set.

```{r}
colnames(iris)=str_replace(colnames(iris), pattern = ".", replacement = "_")
```

In short: `rename()` and `rename_with()` are for *renaming* variables, as their names imply. The `str_` verbs from the stringr package are for editing string-based variabels in your data set. Either works though with a little ingenuity.


## Re-order columns in a data set

Use `relocate()` to change column positions. If you need to move multiple columns at once, this command uses the same syntax as `select()`.

```{r}

mtcars # notice the column order

mtcars %>% relocate(hp:wt, .after= am) %>% head()
```


## Date and time variables

Formatting a column of dates can be extremely helpful if you need to work with time data, but also an extreme pain in the ass if it's not stored correctly. This tutorial will be divided into two parts to cover both scenarios that you could encounter. It requires things to be done in two stages, and very precisely. 

### Part 1: Date-time objects

If you're lucky enough to have a vector of date-times, like what Qualtrics gives you, this will be brainless. Just do the following:

```{r}
example_datetime_data=tibble::tribble(~datetime,
                                      "2010-08-03 00:50:50",
                                      "2010-08-04 01:40:50",
                                      "2010-08-07 21:50:50")

head(example_datetime_data) # stored as character string

# Tidyverse
lubridate::as_date(example_datetime_data$datetime)
```

### Part 2: Date-only objects

If you're unlucky enough to have only dates, and said dates are written in the traditional x/x/xxxx format, this will be an annoyance that has to be done in two stages.

First, assuming your data is already imported and is being stored as a vector of character strings, you have to tell R to adjust the formatting of dates. You cannot change it from a character-based object into a Date or DateTime one until it recognizes the correct formatting.

```{r}
example_date_data=tibble::tribble(~X1,     ~X2,
                                  "8/4/2021",  -49.87,
                                  "8/4/2021",  -13.85,
                                  "8/3/2021",   -7.45,
                                  "8/3/2021", -172.71)

# Correct formatting
example_date_data$X1=format(as.POSIXct(example_date_data$X1,format='%m/%d/%Y'),format='%Y-%m-%d')

head(as_tibble(example_date_data))
```

In the code above, note that there are two `format` commands: The first one tells R how the date data is **currently being stored**, while the second at the end tells it how **you want it to be stored.** In this case, we are changing it from the way we would usually hand write a date (e.g., 10/26/1993) to a format commonly recognized and used in Excel and stats software (1993-10-26). *If your column also has times in it, you also need to include that too!*

Second, you can now correct the object's structure. You can do this with base R's `as.Date()` or tidyverse's `date()` verbs.

```{r eval=FALSE}

# Tidyverse
example_date_data$X1= lubridate::date(example_date_data$X1) 

# Base R version
example_date_data$X1=as.Date(example_date_data$X1)
```

Notice how the object is now stored as the correct type in the table above.

***NOTE!*** This entire process has been included in the `tidy_date()` command in my package, `legaldmlab`.

### Find the difference between two dates/times
```{r , eval=FALSE}
difftime(part_1$end_date[1], part_2$end_date[1], units="days")
```



## Reverse-code a variable

To reverse-score a variable, you should use `car::recode()`
Can be done a few different ways, depending on how many variables you're looking to recode:

```{r eval=FALSE}

# Recode just one variable
df$column=recode(df$column,"1 = 7 ; 2 = 6 ; 3 = 5 ; 5 = 3 ; 6 = 2 ; 7 = 1")

# Recode a select bunch of variables
df=df %>% mutate(across(c(family_close : family_feelings), recode, "1 = 7 ; 2 = 6 ; 3 = 5 ; 5 = 3 ; 6 = 2 ; 7 = 1"))

# Recode the whole damn thing. All columns.
df=df %>% map_df(recode, "1 = 7 ; 2 = 6 ; 3 = 5 ; 5 = 3 ; 6 = 2 ; 7 = 1")
```

## Create a relative ranking among several variables

If you want to create a variable that is an ordinal ranking of other variables, first you need to make sure your data is long-wise. Then, depending on the type of ranking system you want, you'll might need a different ranking command....

- The `min_rank` command from dplyr works in a manner similar to base R's `rank` command. It ranks things like you see in sporting events. For example, if there is a clear winner in a game but 3 people tie for second place, the ranks would look like this: 1,2,2,2,4,5. Notice that the positions are independent from the counts.

- Using the same example from above, if you want the ranks to have no gaps (i.e. 1,2,2,2,3,4), you need to use dplyr's `dense_rank` command.

- In either case, the ranks are generated from lowest to highest, so if you want to flip them around you'll need to include `desc()` in the command.

```{r chapter_3_end}

dat=tibble::tribble(~name, ~score,
                    "bob", 0,
                    "bob", 5,
                    "bob", 50,
                    "bob", 50,
                    "bob", 50,
                    "bob", NA,
                    "alice", 70,
                    "alice", 80,
                    "alice", 90,
                    "alice", 20,
                    "alice", 20,
                    "alice", 1)

dat %>% mutate(ranked = dense_rank(desc(score)))
```


## Manipulating the working environment and many things at once

### Stuff the WHOLE working environment into a list

```{r eval=FALSE}
files=mget(ls())
```


### Extract everything from a list into the environment

```{r eval=FALSE}
list2env(cog_data, globalenv())
```


### Delete everything in the entire environment, except for one item

```{r eval=FALSE}
rm(list=setdiff(ls(), "cog_data")) # delete everything in the local environment except the final data set
```

